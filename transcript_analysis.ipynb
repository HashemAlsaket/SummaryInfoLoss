{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "label_dict = {'politics_cleaned': 0,\n",
    "            'science_cleaned': 1,\n",
    "            'sports_cleaned': 2,\n",
    "            'weather_cleaned': 3,\n",
    "            'worldnews_cleaned': 4}\n",
    "\n",
    "unmask_dict = {0: 'politics',\n",
    "               1: 'science',\n",
    "               2: 'sports',\n",
    "               3: 'weather',\n",
    "               4: 'worldnews'}\n",
    "\n",
    "input_size = 164530 # from X_train.shape[1]\n",
    "output_size = 5 # from len(set(y_train))\n",
    "\n",
    "\n",
    "class DNNLog(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNLog, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = DNNLog(input_size, output_size)\n",
    "checkpoint = torch.load('checkpoint.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('podcast_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filter_nonstr'] = df['transcript'].map(lambda x: 1 if type(x) == str else 0)\n",
    "df = df[df['filter_nonstr'] == 1]\n",
    "df['summary_sentence_length'] = df['summary'].map(lambda x: x.count('.'))\n",
    "df['transcript_sentence_length'] = df['transcript'].map(lambda x: x.count('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_size = 10\n",
    "\n",
    "df['transcript_flat'] = df['transcript'].map(lambda x: x.replace('\\n', ' ').split(' '))\n",
    "df['summary_flat'] = df['summary'].map(lambda x: x.replace('\\n', ' ').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcript_flat'] = df['transcript_flat'].map(lambda x: [y for y in x if y in wv])\n",
    "df['summary_flat'] = df['summary_flat'].map(lambda x: [y for y in x if y in wv])\n",
    "\n",
    "df['w2v_transcript'] = df['transcript_flat'].map(lambda x: [y[:ft_size] for y in wv[x]])\n",
    "df['w2v_summary'] = df['summary_flat'].map(lambda x: [y[:ft_size] for y in wv[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = input_size // 10 # for feature length\n",
    "\n",
    "def pad(arr, padding):\n",
    "    diff = padding - len(arr)\n",
    "    arr = np.pad(arr, ((0, diff), (0, 0)), 'constant')\n",
    "    return arr\n",
    "    \n",
    "df['w2v_transcript_padded'] = df['w2v_transcript'].map(lambda x: pad(x, mx))\n",
    "df['w2v_transcript_padded'] = df['w2v_transcript_padded'].map(lambda x: x.ravel())\n",
    "\n",
    "df['w2v_summary_padded'] = df['w2v_summary'].map(lambda x: pad(x, mx))\n",
    "df['w2v_summary_padded'] = df['w2v_summary_padded'].map(lambda x: x.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = np.array([x.reshape(-1, 1) for x in df['w2v_summary_padded']])\n",
    "summaries = torch.from_numpy(np.asarray(summaries).astype(np.float16)).view(summaries.shape[0], summaries.shape[1])\n",
    "\n",
    "transcripts = np.array([x.reshape(-1, 1) for x in df['w2v_transcript_padded']])\n",
    "transcripts = torch.from_numpy(np.asarray(transcripts).astype(np.float16)).view(transcripts.shape[0], transcripts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_summary = model(summaries.float()).detach().numpy()\n",
    "pred_transcript = model(transcripts.float()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df[['title']]\n",
    "df_transcript = df[['title']]\n",
    "\n",
    "df_summary['summary_scores'] = list(pred_summary)\n",
    "df_transcript['transcript_scores'] = list(pred_transcript)\n",
    "\n",
    "for k in unmask_dict:\n",
    "    df_summary[unmask_dict[k] + '_summary_score'] = [x[k] for x in pred_summary]\n",
    "    \n",
    "for k in unmask_dict:\n",
    "    df_transcript[unmask_dict[k] + '_transcript_score'] = [x[k] for x in pred_transcript]\n",
    "    \n",
    "df_summary = df_summary.sort_values(by=['politics_summary_score', 'science_summary_score', 'sports_summary_score', 'weather_summary_score', 'worldnews_summary_score'], ascending=False)\n",
    "df_summary['summary_rank'] = [x + 1 for x in range(len(df_summary))]\n",
    "df_transcript = df_transcript.sort_values(by=['politics_transcript_score', 'science_transcript_score', 'sports_transcript_score', 'weather_transcript_score', 'worldnews_transcript_score'], ascending=False)\n",
    "df_transcript['transcript_rank'] = [x + 1 for x in range(len(df_transcript))]\n",
    "\n",
    "df_ranks = df_summary.merge(df_transcript, on=['title'])\n",
    "df_ranks = df_ranks[['title', 'summary_rank', 'transcript_rank']]\n",
    "df_ranks = df_ranks.sort_values(by=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ranks.to_csv('podcast_ep_rank_summary_vs_transcript.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
